# Mistral-7B-Instruct-v0.1
Inferencing of Mistral 7B Instruct v0.1 - GGUF  on CPU with a minimalistic CLI-based interface with conversational memory.

Before starting, please note:
This setup assumes you are operating within a virtual environment. Ensure you're referencing the correct directory paths inside this environment when following the steps below.

1. Downloading the Model:
- Download the model using the `automodelforcausallm` function or fetch it directly from the Hugging Face model hub.

2. Updating Model Path:
- After downloading, open the code.
- Find and update the model path to the location where you saved the model inside your virtual environment.

3. Editing the Notepad Bash Scripting File:
- Find the bash scripting file provided. This might have an extension like `.txt` or similar.
- Open it in Notepad or a similar text editor.
- Make the necessary modifications, and ensure reference of the correct directory paths due to the virtual environment.

4. Saving and Executing the Batch File:
- After editing, save the file with a `.bat` extension.
- Run the file either by double-clicking or executing it via command prompt.

5. Using the Offline Model with CLI UI:
- Once you've executed the `.bat` file, the offline model should be operational.
- Interact using the provided Command Line Interface (CLI) for a user-friendly experience.

![Screenshot 2023-09-28 105240](https://github.com/Himanshu8881212/Mistral-7B-Instruct-v0.1/assets/134622172/4b7537d4-b39d-4942-82c6-fcd356792aa8)

When faced with challenges, refer back to this guide.
